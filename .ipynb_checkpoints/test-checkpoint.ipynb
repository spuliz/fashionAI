{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "        \"learning_rate\":1e-3,\n",
    "        \"learning_rate_D\":1e-4,\n",
    "        \"learning_rate_D_local\":1e-4,\n",
    "        \"gan\":\"lsgan\",\n",
    "        \"model\":\"scribbler\",\n",
    "        \"num_epoch\":100,\n",
    "        \"feature_weight\":0,\n",
    "        \"global_pixel_weight_l\":0,\n",
    "        \"local_pixel_weight_l\":1,\n",
    "        \"pixel_weight_ab\":0,\n",
    "        \"pixel_weight_rgb\":0,\n",
    "        \"discriminator_weight\":0,\n",
    "        \"discriminator_local_weight\":0,\n",
    "        \"style_weight\":0,\n",
    "        \"visualize_every\":10,\n",
    "        \"batchsize\": 1,\n",
    "        \"epoch\": 20,\n",
    "        \"cpu\": [0],\n",
    "        \"cpu\": 1,\n",
    "        \"display_port\":8097,\n",
    "        \"data_path\":\"/Users/spuliz/Desktop/NN/textureGan/training_handbags_pretrain\",\n",
    "        \"save_dir\":\"/test\",\n",
    "        \"load_dir\":\"/test\",\n",
    "        \"save_every\":1000,\n",
    "        \"load_epoch\":-1,\n",
    "        \"load_epoch\":-1,\n",
    "        \"load_D\":-1,\n",
    "        \"image_size\":152,\n",
    "        \"resize_to\":300,\n",
    "        \"resize_max\":256,\n",
    "        \"resize_min\":256,\n",
    "        \"patch_size_min\":20,\n",
    "        \"patch_size_max\":40,\n",
    "        \"batch_size\":32,\n",
    "        \"num_input_texture_patch\":2,\n",
    "        \"num_local_texture_patch\":1,\n",
    "        \"color_space\":\"lab\",\n",
    "        \"threshold_D_max\":0.8,\n",
    "        \"content_layers\":\"relu4_2\",\n",
    "        \"style_layers\": \"relu3_2, relu4_2\",\n",
    "        \"use_segmentation_patch\": True,\n",
    "        \"input_texture_patch\": \"dtd_texture\",\n",
    "        \"loss_texture\": \"dtd_texture\",\n",
    "        \"local_texture_size\": 50,\n",
    "        \"texture_discrminator_loss\": True,\n",
    "        \"tv_weight\":1,\n",
    "        \"mode\":\"texture\",\n",
    "        \"visualize_mode\": \"train\",\n",
    "        \"crop\":\"random\",\n",
    "        \"contrast\": True,\n",
    "        \"occlude\": False,\n",
    "        \"checkpoints_path\": \"data/\",\n",
    "        \"noise_gen\": False,\n",
    "        \"absolute_load\": \"\",\n",
    "        \"out\": \"result\",\n",
    "        \"resume\": False,\n",
    "        \"unit\": 1000\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/spuliz/Desktop/NN/textureGan'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it Directory?True\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "def main():\n",
    "\n",
    "  #  print (\"Is it Directory?\" + str(path.isdir('guru99.txt')))\n",
    "   print (\"Is it Directory?\" + str(path.isdir('/Users/spuliz/Desktop/NN/textureGan/training_handbags_pretrain')))\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from main import get_transforms\n",
    "# from dataloader import imfol\n",
    "# from dataloader.imfol import ImageFolder, make_dataset\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "# from utils.visualize import vis_patch, vis_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(args):\n",
    "    transforms_list = [\n",
    "        RandomSizedCrop(args.image_size, args.resize_min, args.resize_max),\n",
    "        RandomHorizontalFlip(),\n",
    "        toTensor()\n",
    "    ]\n",
    "    if args.color_space == 'lab':\n",
    "        transforms_list.insert(2, toLAB())\n",
    "    elif args.color_space == 'rgb':\n",
    "        transforms_list.insert(2, toRGB('RGB'))\n",
    "\n",
    "    transforms = Compose(transforms_list)\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_loader(path):\n",
    "    return pil_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(directory, opt, erode_seg=True):\n",
    "    # opt: 'train' or 'val'\n",
    "    img = glob.glob(osp.join(directory, opt + '_img/*/*.jpg'))\n",
    "    img = sorted(img)\n",
    "    skg = glob.glob(osp.join(directory, opt + '_skg/*/*.jpg'))\n",
    "    skg = sorted(skg)\n",
    "    seg = glob.glob(osp.join(directory, opt + '_seg/*/*.jpg'))\n",
    "    seg = sorted(seg)\n",
    "    txt = glob.glob(osp.join(directory, opt + '_txt/*/*.jpg'))\n",
    "    #txt = glob.glob(osp.join(directory, opt + '_dtd_txt/*/*.jpg'))\n",
    "    extended_txt = []\n",
    "    #import pdb; pdb.set_trace()\n",
    "    for i in range(len(skg)):\n",
    "        extended_txt.append(txt[i%len(txt)])\n",
    "    random.shuffle(extended_txt)\n",
    "    \n",
    "\n",
    "    if erode_seg:\n",
    "        eroded_seg = glob.glob(osp.join(directory, 'eroded_' + opt + '_seg/*/*.jpg'))\n",
    "        eroded_seg = sorted(eroded_seg)\n",
    "        return list(zip(img, skg, seg , eroded_seg, extended_txt))\n",
    "    else:\n",
    "        return list(zip(img, skg, seg, extended_txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolder(data.Dataset):\n",
    "    def __init__(self, opt, root, transform=None, target_transform=None,\n",
    "                 loader=default_loader, erode_seg=True):\n",
    "     \n",
    "        self.root = root\n",
    "        self.imgs = make_dataset(root, opt, erode_seg=erode_seg)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.erode_seg = erode_seg\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.erode_seg:\n",
    "            img_path, skg_path, seg_path, eroded_seg_path, txt_path = self.imgs[index]\n",
    "        else:\n",
    "            img_path, skg_path, seg_path, txt_path = self.imgs[index]\n",
    "        \n",
    "        img = self.loader(img_path)\n",
    "        skg = self.loader(skg_path)\n",
    "        seg = self.loader(seg_path)\n",
    "        txt = self.loader(txt_path)\n",
    "\n",
    "        if self.erode_seg:\n",
    "            eroded_seg = self.loader(eroded_seg_path)\n",
    "        else:\n",
    "            eroded_seg = None\n",
    "\n",
    "        if self.transform is not None:\n",
    "            if self.erode_seg:\n",
    "                img, skg, seg, eroded_seg, txt = self.transform([img, skg, seg, eroded_seg, txt])\n",
    "            else:\n",
    "                img, skg, seg, txt = self.transform([img, skg, seg, txt])\n",
    "                eroded_seg = seg\n",
    "\n",
    "        return img, skg, seg, eroded_seg, txt\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSizedCrop(object):\n",
    "    \"\"\"Crop the given PIL.Image to random size and aspect ratio.\n",
    "    A crop of random size of (0.08 to 1.0) of the original size and a random\n",
    "    aspect ratio of 3/4 to 4/3 of the original aspect ratio is made. This crop\n",
    "    is finally resized to given size.\n",
    "    This is popularly used to train the Inception networks.\n",
    "    Args:\n",
    "        size: size of the smaller edge\n",
    "        interpolation: Default: PIL.Image.BILINEAR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, min_resize=0.08,max_resize=1.0,interpolation=Image.BILINEAR):\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "        self.resize_size = (min_resize,max_resize)\n",
    "\n",
    "    def __call__(self, imgs):\n",
    "        for attempt in range(10):\n",
    "            area = imgs[0].size[0] * imgs[0].size[1]\n",
    "            target_area = random.uniform(self.resize_size[0], self.resize_size[1]) * area\n",
    "            aspect_ratio = random.uniform(3. / 4, 4. / 3)\n",
    "\n",
    "            w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                w, h = h, w\n",
    "\n",
    "            if w <= imgs[0].size[0] and h <= imgs[0].size[1]:\n",
    "                x1 = random.randint(0, imgs[0].size[0] - w)\n",
    "                y1 = random.randint(0, imgs[0].size[1] - h)\n",
    "\n",
    "                imgs = [img.crop((x1, y1, x1 + w, y1 + h)) for img in imgs]\n",
    "                assert([img.size == (w, h) for img in imgs])\n",
    "\n",
    "                return [img.resize((self.size, self.size), self.interpolation) for img in imgs]\n",
    "\n",
    "        # Fallback\n",
    "        scale = Scale(self.size, interpolation=self.interpolation)\n",
    "        crop = CenterCrop(self.size)\n",
    "        return crop(scale(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"Horizontally flip the given PIL.Image randomly with a probability of 0.5.\"\"\"\n",
    "\n",
    "    def __call__(self, imgs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL.Image): Image to be flipped.\n",
    "        Returns:\n",
    "            PIL.Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if random.random() < 0.5:\n",
    "            return [img.transpose(Image.FLIP_LEFT_RIGHT) for img in imgs]\n",
    "        return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toTensor(object):\n",
    "    \"\"\"Transforms a Numpy image to torch tensor\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.space = 'RGB'\n",
    "        \n",
    "    def __call__(self, pics):\n",
    "        imgs = [torch.from_numpy(pic.transpose((2, 0, 1))) for pic in pics]\n",
    "        return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toLAB(object):\n",
    "    \"\"\"\n",
    "    Transform to convert loaded into LAB space. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.space = 'LAB'\n",
    "        \n",
    "    def __call__(self, images):\n",
    "        lab_images = [color.rgb2lab(np.array(image)/255.0) for image in images]\n",
    "        return lab_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>> ])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, imgs):\n",
    "        for t in self.transforms:\n",
    "            imgs = t(imgs)\n",
    "        return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transforms(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path as osp\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = make_dataset(args.data_path, 'val')\n",
    "valDset = ImageFolder('val', args.data_path, transform)\n",
    "val_display_size = 1\n",
    "valLoader = DataLoader(dataset=valDset, batch_size=val_display_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(model, save_path):\n",
    "        \n",
    "    model_state = torch.load(save_path)\n",
    "    \n",
    "    if \"state_dict\" in model_state:\n",
    "        model.load_state_dict(model_state[\"state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(model_state)\n",
    "\n",
    "        model_state = {\n",
    "            'state_dict': model.cpu().state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'iteration': iteration,\n",
    "            'model': args.model,\n",
    "            'color_space': args.color_space,\n",
    "            'batch_size': args.batch_size,\n",
    "            'dataset': dataset,\n",
    "            'image_size': args.image_size\n",
    "        }\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "#     model = torch.cuda.set_device(\"cpu\")\n",
    "#     model.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TextureGAN(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf):\n",
    "        \"\"\"\n",
    "        Defines the necessary modules of the TextureGAN Generator\n",
    "        Input:\n",
    "        - int input_nc : Input number of channels\n",
    "        - int output_nc : Output number of channels\n",
    "        \"\"\"\n",
    "        super(TextureGAN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d\n",
    "        self.batch_norm = nn.BatchNorm2d\n",
    "        self.ngf = ngf\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "\n",
    "        self.res_block = ResidualBlock\n",
    "        self.biup = UpsamplingBlock\n",
    "        self.main_model = MainModel\n",
    "        self.model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        skip_block = nn.Sequential()\n",
    "\n",
    "        skip_block.add_module('main_model', self.main_model(self.input_nc, self.output_nc, self.ngf))\n",
    "        skip_block.add_module('conv_6', self.conv(self.ngf+5, self.ngf*2, 3, 1, 1))\n",
    "        skip_block.add_module('res_block_14', self.res_block(self.ngf*2,self.ngf*2))\n",
    "        skip_block.add_module('res_block_15', self.res_block(self.ngf*2,self.ngf*2))\n",
    "        skip_block.add_module('conv_7', self.conv(self.ngf*2, 3, 3, 1, 1))\n",
    "        skip_block.add_module('batch_9', self.batch_norm(3))\n",
    "\n",
    "        return skip_block\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.legacy as legacy\n",
    "import numpy as np\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf, use_sigmoid):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.input_nc = input_nc\n",
    "        self.ndf = ndf\n",
    "        self.conv = nn.Conv2d\n",
    "        self.batch_norm = nn.BatchNorm2d\n",
    "        self.res_block = ResidualBlock\n",
    "\n",
    "        self.model = self.create_discriminator(use_sigmoid)\n",
    "\n",
    "    def create_discriminator(self, use_sigmoid):\n",
    "        norm_layer = self.batch_norm\n",
    "        ndf = self.ndf  # 32\n",
    "        self.res_block = ResidualBlock\n",
    "        \n",
    "        sequence = [\n",
    "            nn.Conv2d(self.input_nc, self.ndf, kernel_size=9, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(self.ndf, self.ndf * 2, kernel_size=5, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(self.ndf * 2, self.ndf * 8, kernel_size=5, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            self.res_block(self.ndf * 8, self.ndf * 8),\n",
    "            self.res_block(self.ndf * 8, self.ndf * 8),\n",
    "\n",
    "            nn.Conv2d(self.ndf * 8, self.ndf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(self.ndf * 4, 1, kernel_size=4, stride=2, padding=1)\n",
    "        ]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            sequence += [nn.Sigmoid()]\n",
    "\n",
    "        return nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None,\n",
    "                 dilation=(1, 1), residual=True):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride,\n",
    "                             padding=dilation[0], dilation=dilation[0])\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels, stride,\n",
    "                             padding=dilation[1], dilation=dilation[1])\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.residual = residual\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        if self.residual:\n",
    "            out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsamplingBlock(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, kernel, stride, pad):\n",
    "        \"\"\"\n",
    "        Single block of upsampling operation\n",
    "        Input:\n",
    "        - int input_nc    : Input number of channels\n",
    "        - int output_nc   : Output number of channels\n",
    "        - int kernel      : Kernel size\n",
    "        - int stride\t  : Stride length\n",
    "        - int pad         : Padd_moduleing\n",
    "        \"\"\"\n",
    "        super(UpsamplingBlock, self).__init__()\n",
    "\n",
    "        conv = nn.Conv2d\n",
    "        biup = nn.UpsamplingBilinear2d\n",
    "\n",
    "        block = nn.Sequential()\n",
    "        block.add_module('conv_1', conv(input_nc, output_nc, kernel, stride,pad))\n",
    "        block.add_module('upsample_2', biup(scale_factor=2))\n",
    "\n",
    "        self.biup_block = block\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.biup_block(x)\n",
    "\n",
    "# 3x3 Convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1, padding=1, dilation=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                     stride=stride, padding=padding, dilation=dilation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf):\n",
    "        \"\"\"\n",
    "        Function which pieces together the model\n",
    "        \"\"\"\n",
    "        super(MainModel, self).__init__()\n",
    "        self.conv = nn.Conv2d\n",
    "        self.batch_norm = nn.BatchNorm2d\n",
    "        self.ngf = ngf\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "\n",
    "        self.res_block = ResidualBlock\n",
    "        self.biup = UpsamplingBlock\n",
    "        model = nn.Sequential()\n",
    "        \n",
    "        model.add_module('conv_1', self.conv(input_nc,ngf,3,1,1))\n",
    "        model.add_module('batch_1', self.batch_norm(ngf))\n",
    "        model.add_module('norm_1', nn.ReLU(True))\n",
    "\n",
    "        model.add_module('res_block_1', self.res_block(ngf,ngf))\n",
    "        model.add_module('conv_2', self.conv(ngf,ngf*2,3,2,1))\n",
    "        model.add_module('batch_2',self.batch_norm(ngf*2))\n",
    "        model.add_module('norm_2', nn.ReLU(True))\n",
    "\n",
    "        model.add_module('res_block_2', self.res_block(ngf*2,ngf*2))\n",
    "\n",
    "        model.add_module('conv_3',self.conv(ngf*2,ngf*4,3,2,1))\n",
    "        model.add_module('batch_3',self.batch_norm(ngf*4))\n",
    "        model.add_module('norm_3',nn.ReLU(True))\n",
    "\n",
    "        model.add_module('res_block_3',self.res_block(ngf*4,ngf*4))\n",
    "\n",
    "        model.add_module('conv_4',self.conv(ngf*4,ngf*8,3,2,1))\n",
    "        model.add_module('batch_4',self.batch_norm(ngf*8))\n",
    "        model.add_module('norm_4',nn.ReLU(True))\n",
    "        \n",
    "        model.add_module('res_block_4',self.res_block(ngf*8,ngf*8))\n",
    "        model.add_module('res_block_5',self.res_block(ngf*8,ngf*8))\n",
    "        model.add_module('res_block_6',self.res_block(ngf*8,ngf*8))\n",
    "        model.add_module('res_block_7',self.res_block(ngf*8,ngf*8))\n",
    "        model.add_module('res_block_8',self.res_block(ngf*8,ngf*8))\n",
    "\n",
    "        model.add_module('upsampl_1',self.biup(ngf*8,ngf*4,3,1,1))\n",
    "        model.add_module('batch_5',self.batch_norm(ngf*4))\n",
    "        model.add_module('norm_5',nn.ReLU(True))\n",
    "        model.add_module('res_block_9',self.res_block(ngf*4,ngf*4))\n",
    "        model.add_module('res_block_10',self.res_block(ngf*4,ngf*4))\n",
    "\n",
    "        model.add_module('upsampl_2',self.biup(ngf*4,ngf*2,3,1,1))\n",
    "        model.add_module('batch_6',self.batch_norm(ngf*2))\n",
    "        model.add_module('norm_6',nn.ReLU(True))\n",
    "        model.add_module('res_block_11',self.res_block(ngf*2,ngf*2))\n",
    "        model.add_module('res_block_12',self.res_block(ngf*2,ngf*2))\n",
    "\n",
    "        model.add_module('upsampl_3',self.biup(ngf*2,ngf,3,1,1))\n",
    "        model.add_module('batch_7',self.batch_norm(ngf))\n",
    "        model.add_module('norm_7',nn.ReLU(True))\n",
    "        model.add_module('res_block_13',self.res_block(ngf,ngf))\n",
    "        model.add_module('batch_8',self.batch_norm(ngf))\n",
    "\n",
    "        self.main_model = model\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat((self.main_model(x), x), 1)\n",
    "        #return self.main_model(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextureGAN(\n",
       "  (model): Sequential(\n",
       "    (main_model): MainModel(\n",
       "      (main_model): Sequential(\n",
       "        (conv_1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batch_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_1): ReLU(inplace=True)\n",
       "        (res_block_1): ResidualBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (batch_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_2): ReLU(inplace=True)\n",
       "        (res_block_2): ResidualBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (batch_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_3): ReLU(inplace=True)\n",
       "        (res_block_3): ResidualBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv_4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (batch_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_4): ReLU(inplace=True)\n",
       "        (res_block_4): ResidualBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (res_block_5): ResidualBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (res_block_6): ResidualBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (res_block_7): ResidualBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (res_block_8): ResidualBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (upsampl_1): UpsamplingBlock(\n",
       "          (biup_block): Sequential(\n",
       "            (conv_1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (upsample_2): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
       "          )\n",
       "        )\n",
       "        (batch_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_5): ReLU(inplace=True)\n",
       "        (res_block_9): ResidualBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (res_block_10): ResidualBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (upsampl_2): UpsamplingBlock(\n",
       "          (biup_block): Sequential(\n",
       "            (conv_1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (upsample_2): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
       "          )\n",
       "        )\n",
       "        (batch_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_6): ReLU(inplace=True)\n",
       "        (res_block_11): ResidualBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (res_block_12): ResidualBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (upsampl_3): UpsamplingBlock(\n",
       "          (biup_block): Sequential(\n",
       "            (conv_1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (upsample_2): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
       "          )\n",
       "        )\n",
       "        (batch_7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_7): ReLU(inplace=True)\n",
       "        (res_block_13): ResidualBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (batch_8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_6): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (res_block_14): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (res_block_15): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_7): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batch_9): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change to your location\n",
    "model_location = '/Users/spuliz/Desktop/NN/textureGan/textureD_final_allloss_handbag_3300.pth'\n",
    "\n",
    "netG = TextureGAN(5, 3, 32)\n",
    "load_network(netG, model_location)\n",
    "\n",
    "netG.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scale(object):\n",
    "    \"\"\"Rescale multiple input PIL.Image to the given size.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size. If size is a sequence like\n",
    "            (w, h), output size will be matched to this. If size is an int,\n",
    "            smaller edge of the image will be matched to this number.\n",
    "            i.e, if height > width, then image will be rescaled to\n",
    "            (size * height / width, size)\n",
    "        interpolation (int, optional): Desired interpolation. Default is\n",
    "            ``PIL.Image.BILINEAR``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        assert isinstance(size, int) or (isinstance(size, collections.Iterable) and len(size) == 2)\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "        self.transform = torchvision.transforms.Scale(size)\n",
    "\n",
    "    def __call__(self, imgs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            imgs (list of PIL.Image): Images to be scaled.\n",
    "        Returns:\n",
    "            list of PIL.Image: Rescaled images.\n",
    "        \"\"\"       \n",
    "        return [self.transform(img) for img in imgs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenterCrop(object):\n",
    "    \"\"\"Crops the given PIL.Image at the center.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size of the crop. If size is an\n",
    "            int instead of sequence like (h, w), a square crop (size, size) is\n",
    "            made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "        self.transform = torchvision.transforms.CenterCrop(size)\n",
    "\n",
    "    def __call__(self, imgs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            imgs (PIL.Image): Image to be cropped.\n",
    "        Returns:\n",
    "            PIL.Image: Cropped image.\n",
    "        \"\"\"\n",
    "        return [self.transform(img) for img in imgs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "from skimage import color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = valLoader.__iter__().__next__()\n",
    "# from utils import transforms as custom_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(val_loader,xcenter,ycenter,patch_size,num_patch):\n",
    "    img, skg, seg, eroded_seg, txt = val_loader\n",
    "    img = normalize_lab(img)\n",
    "    skg = normalize_lab(skg)\n",
    "    txt = normalize_lab(txt)\n",
    "    seg = normalize_seg(seg)\n",
    "    eroded_seg = normalize_seg(eroded_seg)\n",
    "\n",
    "    bs, w, h = seg.size()\n",
    "\n",
    "    seg = seg.view(bs, 1, w, h)\n",
    "    seg = torch.cat((seg, seg, seg), 1)\n",
    "\n",
    "    eroded_seg = eroded_seg.view(bs, 1, w, h)\n",
    "    eroded_seg = torch.cat((eroded_seg, eroded_seg, eroded_seg), 1)\n",
    "\n",
    "    temp = torch.ones(seg.size()) * (1 - seg).float()\n",
    "    temp[:, 1, :, :] = 0  # torch.ones(seg[:,1,:,:].size())*(1-seg[:,1,:,:]).float()\n",
    "    temp[:, 2, :, :] = 0  # torch.ones(seg[:,2,:,:].size())*(1-seg[:,2,:,:]).float()\n",
    "\n",
    "    txt = txt.float() * seg.float() + temp\n",
    "\n",
    "    patchsize = args.local_texture_size\n",
    "    batch_size = bs\n",
    "    if xcenter < 0 or ycenter < 0:\n",
    "        inp, texture_loc = gen_input_rand(txt, skg, eroded_seg[:, 0, :, :] * 100,\n",
    "                                              patch_size, patch_size,\n",
    "                                              num_patch)\n",
    "    else:\n",
    "        inp, texture_loc = gen_input_exact(txt, skg, eroded_seg[:, 0, :, :] * 100,xcenter,ycenter,patch_size,1)\n",
    "        \n",
    "    return inp,texture_loc \n",
    "def get_inputv(inp):\n",
    "    device = torch.device(\"cpu\")\n",
    "    input_stack = torch.FloatTensor().to(device)\n",
    "    input_stack.resize_as_(inp.float()).copy_(inp)\n",
    "    inputv = Variable(input_stack)\n",
    "    return inputv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lab(lab_img):\n",
    "    \"\"\"\n",
    "    Normalizes the LAB image to lie in range 0-1\n",
    "    \n",
    "    Args:\n",
    "    lab_img : torch.Tensor img in lab space\n",
    "    \n",
    "    Returns:\n",
    "    lab_img : torch.Tensor Normalized lab_img \n",
    "    \"\"\"\n",
    "    mean = torch.zeros(lab_img.size())\n",
    "    stds = torch.zeros(lab_img.size())\n",
    "    \n",
    "    mean[:,0,:,:] = 50\n",
    "    mean[:,1,:,:] = 0\n",
    "    mean[:,2,:,:] = 0\n",
    "    \n",
    "    stds[:,0,:,:] = 50\n",
    "    stds[:,1,:,:] = 128\n",
    "    stds[:,2,:,:] = 128\n",
    "    \n",
    "    return (lab_img.double() - mean.double())/stds.double()\n",
    "\n",
    "def normalize_seg(seg):\n",
    "    \"\"\"\n",
    "    Normalizes the LAB image to lie in range 0-1\n",
    "    \n",
    "    Args:\n",
    "    lab_img : torch.Tensor img in lab space\n",
    "    \n",
    "    Returns:\n",
    "    lab_img : torch.Tensor Normalized lab_img \n",
    "    \"\"\"\n",
    "    result = seg[:,0,:,:]\n",
    "    if torch.max(result) >1:\n",
    "        result = result/100.0\n",
    "    result = torch.round(result)\n",
    "    \n",
    "    \n",
    "    return result\n",
    "\n",
    "def normalize_rgb(rgb_img):\n",
    "    \"\"\"\n",
    "    Normalizes the LAB image to lie in range 0-1\n",
    "    \n",
    "    Args:\n",
    "    lab_img : torch.Tensor img in lab space\n",
    "    \n",
    "    Returns:\n",
    "    lab_img : torch.Tensor Normalized lab_img \n",
    "    \"\"\"\n",
    "    mean = torch.zeros(rgb_img.size())\n",
    "    stds = torch.zeros(rgb_img.size())\n",
    "    \n",
    "    mean[:,0,:,:] = 0.485\n",
    "    mean[:,1,:,:] = 0.456\n",
    "    mean[:,2,:,:] = 0.406\n",
    "    \n",
    "    stds[:,0,:,:] = 0.229\n",
    "    stds[:,1,:,:] = 0.224\n",
    "    stds[:,2,:,:] = 0.225\n",
    "    \n",
    "    return (rgb_img.double() - mean.double())/stds.double()\n",
    "   \n",
    "    \n",
    "def denormalize_lab(lab_img):\n",
    "    \"\"\"\n",
    "    Normalizes the LAB image to lie in range 0-1\n",
    "    \n",
    "    Args:\n",
    "    lab_img : torch.Tensor img in lab space\n",
    "    \n",
    "    Returns:\n",
    "    lab_img : torch.Tensor Normalized lab_img \n",
    "    \"\"\"\n",
    "    mean = torch.zeros(lab_img.size())\n",
    "    stds = torch.zeros(lab_img.size())\n",
    "    \n",
    "    mean[:,0,:,:] = 50\n",
    "    mean[:,1,:,:] = 0\n",
    "    mean[:,2,:,:] = 0\n",
    "    \n",
    "    stds[:,0,:,:] = 50\n",
    "    stds[:,1,:,:] = 128\n",
    "    stds[:,2,:,:] = 128\n",
    "\n",
    "    return lab_img.double() *stds.double() + mean.double()\n",
    "\n",
    "\n",
    "def denormalize_rgb(rgb_img):\n",
    "    \"\"\"\n",
    "    Normalizes the LAB image to lie in range 0-1\n",
    "    \n",
    "    Args:\n",
    "    lab_img : torch.Tensor img in lab space\n",
    "    \n",
    "    Returns:\n",
    "    lab_img : torch.Tensor Normalized lab_img \n",
    "    \"\"\"\n",
    "    mean = torch.zeros(rgb_img.size())\n",
    "    stds = torch.zeros(rgb_img.size())\n",
    "    \n",
    "    mean[:,0,:,:] = 0.485\n",
    "    mean[:,1,:,:] = 0.456\n",
    "    mean[:,2,:,:] = 0.406\n",
    "    \n",
    "    stds[:,0,:,:] = 0.229\n",
    "    stds[:,1,:,:] = 0.224\n",
    "    stds[:,2,:,:] = 0.225\n",
    "\n",
    "    return rgb_img.double() *stds.double() + mean.double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_input_rand(img, skg, seg, size_min=40, size_max=60, num_patch=1):\n",
    "    # generate input skg with random patch from img\n",
    "    # input img,skg [bsx3xwxh], xcenter,ycenter, size\n",
    "    # output bsx5xwxh\n",
    "    \n",
    "    bs, c, w, h = img.size()\n",
    "    results = torch.Tensor(bs, 5, w, h)\n",
    "    texture_info = []\n",
    "\n",
    "    # text_info.append([xcenter,ycenter,crop_size])\n",
    "    seg = seg / torch.max(seg) #make sure it's 0/1\n",
    "    \n",
    "    seg[:,0:int(math.ceil(size_min/2)),:] = 0\n",
    "    seg[:,:,0:int(math.ceil(size_min/2))] = 0\n",
    "    seg[:,:,int(math.floor(h-size_min/2)):h] = 0\n",
    "    seg[:,int(math.floor(w-size_min/2)):w,:] = 0\n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(bs):\n",
    "        counter = 0\n",
    "        ini_texture = torch.ones(img[0].size()) * (1)\n",
    "        ini_mask = torch.ones((1, w, h)) * (-1)\n",
    "        temp_info = []\n",
    "        \n",
    "        for j in range(num_patch):\n",
    "            crop_size = int(rand_between(size_min, size_max))\n",
    "            \n",
    "            seg_index_size = seg[i,:,:].view(-1).size()[0]\n",
    "            seg_index = torch.arange(0,seg_index_size)\n",
    "            seg_one = seg_index[seg[i,:,:].view(-1)==1]\n",
    "            if len(seg_one) != 0:\n",
    "                seg_select_index = int(rand_between(0,seg_one.view(-1).size()[0]-1))\n",
    "                x,y = get_coor(seg_one[seg_select_index],seg[i,:,:].size())\n",
    "            else:\n",
    "                x,y = (w/2, h/2)\n",
    "            \n",
    "            temp_info.append([x, y, crop_size])\n",
    "            res = gen_input(img[i], skg[i], ini_texture, ini_mask, x, y, crop_size)\n",
    "\n",
    "            ini_texture = res[1:4, :, :]\n",
    "\n",
    "        texture_info.append(temp_info)\n",
    "        results[i, :, :, :] = res\n",
    "    return results, texture_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_between(a, b):\n",
    "    return a + torch.round(torch.rand(1) * (b - a))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coor(index, size):\n",
    "    index = int(index)\n",
    "    #get original coordinate from flatten index for 3 dim size\n",
    "    w,h = size\n",
    "    \n",
    "    return ((index%(w*h))/h, ((index%(w*h))%h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_input(img, skg, ini_texture, ini_mask, xcenter=64, ycenter=64, size=40):\n",
    "    # generate input skg with random patch from img\n",
    "    # input img,skg [bsx3xwxh], xcenter,ycenter, size\n",
    "    # output bsx5xwxh\n",
    "\n",
    "    w, h = img.size()[1:3]\n",
    "    # print w,h\n",
    "    xstart = max(int(xcenter - size / 2), 0)\n",
    "    ystart = max(int(ycenter - size / 2), 0)\n",
    "    xend = min(int(xcenter + size / 2), w)\n",
    "    yend = min(int(ycenter + size / 2), h)\n",
    "\n",
    "    input_texture = ini_texture  # torch.ones(img.size())*(1)\n",
    "    input_sketch = skg[0:1, :, :]  # L channel from skg\n",
    "    input_mask = ini_mask  # torch.ones(input_sketch.size())*(-1)\n",
    "\n",
    "    input_mask[:, xstart:xend, ystart:yend] = 1\n",
    "\n",
    "    input_texture[:, xstart:xend, ystart:yend] = img[:, xstart:xend, ystart:yend].clone()\n",
    "\n",
    "    return torch.cat((input_sketch.cpu().float(), input_texture.float(), input_mask), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_image(img, color='lab'):\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cpu()\n",
    "\n",
    "    img = img.numpy()\n",
    "\n",
    "    if color == 'lab':\n",
    "        ToRGB = toRGB()\n",
    "    elif color =='rgb':\n",
    "        ToRGB = toRGB('RGB')\n",
    "\n",
    "    # print np.shape(img)\n",
    "    img_np = ToRGB(img)\n",
    "\n",
    "    return img_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toRGB_(object):\n",
    "    \"\"\"\n",
    "    Transform to convert loaded into LAB space. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.space = 'LAB'\n",
    "        \n",
    "    def __call__(self, images):\n",
    "        images = np.transpose(images.numpy(), (1, 2, 0))\n",
    "        rgb_images = [(np.array(image)/255.0) for image in images]\n",
    "        return rgb_images\n",
    "\n",
    "\n",
    "class toRGB(object):\n",
    "    \"\"\"\n",
    "    Transform to convert loaded into RGB color space. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, space ='LAB'):\n",
    "        self.space = space\n",
    "        \n",
    "    def __call__(self, images):\n",
    "        if self.space =='LAB':\n",
    "            # npimg = np.transpose(np.array(images), (1, 2, 0))\n",
    "            # print(image)\n",
    "            rgb_img = [np.transpose(color.lab2rgb(np.transpose(image, (1,2,0))), (2,0,1)) for image in images]\n",
    "        elif self.space =='RGB':\n",
    "            # print np.shape(images)\n",
    "            # images = np.transpose(images.numpy(), (1, 2, 0))\n",
    "            rgb_img = [(np.array(image)/255.0) for image in images]\n",
    "\n",
    "        return rgb_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_patch(img, skg, texture_location, color='lab'):\n",
    "    batch_size, _, _, _ = img.size()\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cpu()\n",
    "        skg = skg.cpu()\n",
    "\n",
    "    img = img.numpy()\n",
    "    skg = skg.numpy()\n",
    "\n",
    "    if color == 'lab':\n",
    "        ToRGB = toRGB()\n",
    "        \n",
    "    elif color =='rgb':\n",
    "        ToRGB = toRGB('RGB')\n",
    "        \n",
    "    img_np = ToRGB(img)\n",
    "    skg_np = ToRGB(skg)\n",
    "\n",
    "    vis_skg = np.copy(skg_np)\n",
    "    vis_img = np.copy(img_np)\n",
    "\n",
    "    # print np.shape(vis_skg)\n",
    "    for i in range(batch_size):\n",
    "        for text_loc in texture_location[i]:\n",
    "            xcenter, ycenter, size = text_loc\n",
    "            xcenter = max(xcenter-int(size/2),0) + int(size/2)\n",
    "            ycenter = max(ycenter-int(size/2),0) + int(size/2)\n",
    "            vis_skg[\n",
    "                i, :,\n",
    "                int(xcenter-size/2):int(xcenter+size/2),\n",
    "                int(ycenter-size/2):int(ycenter+size/2)\n",
    "            ] = vis_img[\n",
    "                    i, :,\n",
    "                    int(xcenter-size/2):int(xcenter+size/2),\n",
    "                    int(ycenter-size/2):int(ycenter+size/2)\n",
    "                ]\n",
    "\n",
    "    return vis_skg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 151.5, 151.5, -0.5)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "color_space = 'lab'\n",
    "\n",
    "data = valLoader.__iter__().__next__()\n",
    "\n",
    "img, skg, seg, eroded_seg, txt = data\n",
    "\n",
    "img = normalize_lab(img)\n",
    "skg = normalize_lab(skg)\n",
    "txt = normalize_lab(txt)\n",
    "seg = normalize_seg(seg)\n",
    "eroded_seg = normalize_seg(eroded_seg)\n",
    "inp,texture_loc = get_input(data,-1,-1,30,1)\n",
    "\n",
    "seg = seg!=0\n",
    "\n",
    "model = netG\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "inpv = get_inputv(inp.to(device))\n",
    "output = model(inpv.to(device))\n",
    "\n",
    "out_img = vis_image(denormalize_lab(output.data.double().cpu()),\n",
    "                                    color_space)\n",
    "inp_img = vis_patch(denormalize_lab(txt.cpu()),\n",
    "                           denormalize_lab(skg.cpu()),\n",
    "                            texture_loc,\n",
    "                            color_space)\n",
    "tar_img = vis_image(denormalize_lab(img.cpu()),\n",
    "                        color_space)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.transpose(inp_img[0],(1, 2, 0)))\n",
    "plt.axis('off')\n",
    "#plt.figure()  \n",
    "plt.figure()\n",
    "plt.imshow(np.transpose(out_img[0],(1, 2, 0)))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
